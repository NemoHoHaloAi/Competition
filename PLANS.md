# PLANS

All I did in last two years:
- form `2017-10-25` to `2018-10-18`, 1 year, I done the ML class and ML+ class.
- from `2018-10-19` to `2019-11-05`, 1 year, I only done 3 projects(Titanic, House-Price, DigitReconize), starting 2 projects(ASHRA, Future-Sales-Predict) in kaggle.

In one and half years ago, I writed this:

> **Get a job about machine learning whatever how much job-pay is!!!**<br>
>> I am 26 old now, I have nothing by myself to proud. The house? my parent pay it, the job? it just so-so. I am even not better than my father on his 26 old, and I have University degree. So what I do in shenzhen from 2015 year until now. Everyone I know is working hard but me, I feel shame on myself. But good news is I still have time to find and learn how to be better. Someone will say I just follow the wind of machine learning, but I dont give a shit, it will be difficult, and job-pay will be lesser, but I will get it and do it well, I will show everyone I can do this well. Of cause first I must to finish the udacity machine learning lesson.
    
And now, I am 27, still do nothing, I am scare now, maybe this is a wrong way and I am not a hard-work person, maybe I should always be a software-engineer not a MLer, but I want to try last time, from now to `2020-05-01`, I will study harder and harder, follow my plan(kaggle projects, kaggle kernels, books and videos), I will give up if I can not get a ML job between `2020-03` and `2020-04`, please be harder and dont make yourself regretting, when you feel tired, you look around your friends(xing, qi, rui), everybody work hard and get something but me, I should work harder than them.

## TARGET

Get a job about `Time-Series`, `Sale-Predict` and `Machine Learning`.

## Timetable

- work day:
    - `9:00` ~ `10:00`: relax;
    - `10:00` ~ `12:30`: work;
    - `12:30` ~ `14:00`: lunch and take a nap;
    - `14:00` ~ `19:30`: work;
    - `19:30` ~ `21:00`: dinner and take a shower;
    - `21:00` ~ `24:00`: study;
- rest day:
    - `10:00` ~ `12:00`: relax;
    - `12:00` ~ `14:00`: breakfast and take a walk and shop for dinner;
    - `14:00` ~ `18:00`: study;
    - `18:00` ~ `20:00`: dinner and take a shower and maybe take a walk;
    - `20:00` ~ `24:00`: study;
    
## DETAIL

When you waiting for the code run, you best to do something else, like learn from kernels, read book, watch video, write note, etc.

## PLAN-corgi ![icon](https://img.shields.io/badge/doing-35%25-green)

cycle time: from `2019-11-05` to `2019-11-30`;

1. ![icon](https://img.shields.io/badge/doing|A-90%25-green) finish [future-price-predict project](https://www.kaggle.com/holoong9291/predict-future-sales) with the good kernel
    1. deathline: `2019-11-10`;
    2. now: fix and update with [the good kernel](https://www.kaggle.com/dlarionov/feature-engineering-xgboost);
    3. and: model stack, correct factor;
    4. last: up to Top10%;
2. ![icon](https://img.shields.io/badge/done-100%25-lightgrey) learn how to work with time series with TS kernels
    1. deathline: `2019-11-17`;
    2. now: start with https://www.kaggle.com/shivamb/data-science-glossary-on-kaggle ;
    3. first(common): https://www.kaggle.com/thebrownviking20/everything-you-can-do-with-a-time-series ;
    4. second(ARIMA): https://www.kaggle.com/myonin/bitcoin-price-prediction-by-arima ;
3. another competitions
    - ![icon](https://img.shields.io/badge/done|A-100%25-lightgrey)[NFL Big Data Bowl](https://www.kaggle.com/c/nfl-big-data-bowl-2020/data)
        1. deathline: `2019-11-28`;
        2. [github project link](https://github.com/NemoHoHaloAi/Competition/tree/master/kaggle/Topxxx-yyy-zzz-NFL-Big-Data-Bowl)
        3. [start with](https://www.kaggle.com/gertjac/regression-approach)
        4. 等待竞赛结束后整理总结分析，学到很多，但是不得不说的是差距依然很大；
    - ![icon](https://img.shields.io/badge/todo|B-0%25-orange)[Corporación Favorita Grocery Sales Forecasting](https://www.kaggle.com/c/favorita-grocery-sales-forecasting)
        1. deathline: `2019-12-15`;
        2. [github project link](https://github.com/NemoHoHaloAi/Competition/tree/master/kaggle/Topxxx-yyy-zzz-Large-Grocery-Chain-Predict)
        3. [start with](https://www.kaggle.com/ceshine/lgbm-starter)
    - ![icon](https://img.shields.io/badge/doing|A-90%25-green)[Store Item Demand Forecasting](https://www.kaggle.com/c/demand-forecasting-kernels-only)
        1. deathline: `2019-12-15`;
        2. [github project link](https://github.com/NemoHoHaloAi/Competition/tree/master/kaggle/Topxxx-yyy-zzz-Store-Item-Demand-Forecasting-Challenge)
        3. [notebook](https://www.kaggle.com/holoong9291/store-item-demand-predict)
    - ![icon](https://img.shields.io/badge/doing|A-50%25-green)[Recruit Restaurant Visitor Forecasting](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting)
        1. deathline: `2020-01-05`;
        2. [github project link](https://github.com/NemoHoHaloAi/Competition/tree/master/kaggle/Topxxx-yyy-zzz-Recruit-Restaurant-Visitor-Forecasting)
        3. [notebook](https://www.kaggle.com/holoong9291/recruit-restaurant-visitor-forecasting)
    - ![icon](https://img.shields.io/badge/doing|A-1%25-green)[Web Traffic Time Series Forecasting](https://www.kaggle.com/c/web-traffic-time-series-forecasting)
        1. deathline: `2019-01-15`;
        2. [github project link](xxxx)
        3. [notebook](https://www.kaggle.com/holoong9291/web-traffic-time-series-forecasting)
4. ![icon](https://img.shields.io/badge/todo|B-0%25-orange) Build a notebook call time-series common workflow, and publish.
    1. deathline: `2019-01-20`
5. ![icon](https://img.shields.io/badge/todo|B-33%25-green) [summary](https://github.com/NemoHoHaloAi/Competition/tree/master/memo/Time-Series) of time-series projects(House-Price, Rossmann, Predict-Future-Sales)
    1. deathline: `2019-12-20`;
    2. target: can throw into the introduction;
6. ![icon](https://img.shields.io/badge/done|B-100%25-lightgrey) summary of time-series kernels(Time-Series projects)
    1. deathline: `2019-11-20`;
7. ![icon](https://img.shields.io/badge/todo|B-0%25-orange) summary of time-series(All about Time-Series)
    1. deathline: `2019-12-25`;
8. ![icon](https://img.shields.io/badge/todo|S-0%25-orange) update introduction with some project, and add detail in project
    1. deathline: `2019-12-31`;
    2. target: can give it to the interviewers and show my Time-Series skills;

## PLAN-jaguar ![icon](https://img.shields.io/badge/doing|A-15%25-green)

cycle time: from `2019-12-01` to `2019-12-31`;

Learn theoretical knowledge about ML:
1. ![icon](https://img.shields.io/badge/todo-0%25-orange) 李航《统计学习方法》+[code](https://github.com/WenDesi/lihang_book_algorithm)：建议边看书边手推公式然后对着GitHub一边敲代码;
2. ![icon](https://img.shields.io/badge/done|A-100%25-lightgrey) 林轩田《机器学习基石》+[video+link+note](https://github.com/NemoHoHaloAi/NTU-HsuanTienLin-MachineLearning/tree/master/Machine%20Learning%20Foundations);
3. ![icon](https://img.shields.io/badge/todo|A-5%25-orange) 林轩田《机器学习技法》+[video+link+note](https://github.com/NemoHoHaloAi/NTU-HsuanTienLin-MachineLearning/tree/master/Machine%20Learning%20Techniques);
4. ![icon](https://img.shields.io/badge/todo-0%25-orange) [线性代数和微积分](https://github.com/NemoHoHaloAi/OpenCourseCatalog);
5. ![icon](https://img.shields.io/badge/todo-0%25-orange) [Spark in Python](http://spark.apache.org/docs/latest/api/python/index.html);
6. ![icon](https://img.shields.io/badge/todo|A-1%25-orange) 西瓜书;
7. [数学基础](https://www.jiqizhixin.com/articles/2018-04-12-4)：
    1. ![icon](https://img.shields.io/badge/doing|S-3%25-green) 微积分：https://space.bilibili.com/88461692/channel/detail?cid=13407
        - [微积分到底是什么](https://zhuanlan.zhihu.com/p/94592123)
        - 普林斯顿微积分读本：30章，每章10\~30页，预计工作日2\~3天1章，休息日1天1章，即一周4\~5章，完成需要大约6周；
        - deathline: `2020-02-15`；
    2. 线性代数：https://www.bilibili.com/video/av6731067
    3. [另一篇文章](https://zhuanlan.zhihu.com/p/36357540):微积分、线代、概率论、最优化；
    4. 矩阵求导
    5. 概率论+统计：陈希儒的概率论与数理统计
    6. 线性规划+凸优化
    7. 数值计算、数值线代

## DAILY MEMO

目前最需要的是什么？
1. 拿得出手的项目；
2. 实际项目中遇到的问题、解决方案、各项技能知识；
3. 基础知识；

同时进行的事：NFL、KernelLearn、基石课程；

- 2019-11-06: 完成Future-Sales-Predict项目从good-kernel上借鉴部分，目前完成了预处理、特征工程部分；
- 2019-11-07: 完成数据分割、baseline、遍历方式优化部分、数据转换（对比多种方式并分别应用到特征上）、数据转换无法降低skew的原因及处理方法、绘制整个过程中的数据结构变化；
- 2019-11-08: 数据转换后转换回来的问题、调整数据转换代码到合入test前并分别对matrix和train做转换、数据结构变化收尾；
- 2019-11-09: 基石-chapter2，基石-chapter3；
- 2019-11-10: 预测结果与实际结果对比、生成结果文件、计算分数(0.95)、模型堆叠、开放kernel并增加baseon和优化修改点，基石-chapter4，基石-chapter5，基石-chapter6；
- 2019-11-11: 离线运行Future-Sales-Predict、Kernel(基于TS数据能做的所有事)；
- 2019-11-12: Kernel(基于TS数据能做的所有事)-surplus；
- 2019-11-13: Kernel(Bitcoin-Predict-by-ARIMA)；
- 2019-11-14: Kernel(Bert NFL started Kernel)、NFL-Big-Data-Bowl(开始、数据加载、定义问题、评价函数、Preprocess)；
- 2019-11-15: NFL-Big-Data-Bowl(调研理解数据和问题、Preprocess)；
- 2019-11-16: NFL-Big-Data-Bowl(EDA、FE（FE部分暂时不考虑聚合的球员信息挖掘）)；
- 2019-11-17: NFL-Big-Data-Bowl(聚合后球员信息挖掘、算法替换为性能更好的，比如xgboost、模型堆叠集成)；
- 2019-11-18: NFL-Big-Data-Bowl(还有几个需要处理的特征：Location，PlayerCollegeName，Stadium，GameWeather，OffensePersonnel，DefensePersonnel，统一处理这一类问题，test中的类别不存在train中时如何处理、设计新的特征提交结果)；
- 2019-11-19: 修复一些bug，提交结果、score上看没有提升；
- 2019-11-20: 开始在22个球员的位置、速度、角度等信息上进行挖掘，得到的信息不足以提高模型的准确性；
- 2019-11-24: 开始考虑用简单特征、复杂模型来处理，基石-chapter7、8、9；
- 2019-11-25~27: 离线运行、分kernel验证、模型融合；
- 2019-12-02: NFL暂停等待竞赛结束后总结整理、Future-Sales-Predict暂停；
- 2019-12-08: Store-Item-Demand基础处理、ARIMA预测；
- 2019-12-09: Store-Item-Demand prophet预测、ARIMA参数3噪声的移动平均确定，为ARIMA加入网格搜索最优参数、xgboost第一次预测（尽可能做的少，直接预测结果，看rmse）、基石-chapter10；
- 2019-12-10: Store-Item-Demand ARIMA最优参数确定(目前只通过store==1&item==1的数据来进行网格搜索,711)、xgboost增加更多FE部分、基石-chapter11；
- 2019-12-11: Store-Item-Demand(拆分到3个notebook，内存优化，继续XGBoost版本特征工程)；
- 2019-12-12: Store-Item-Demand(XGBoost版本FE初版，三个版本生成对应的结果文件)；
- 2019-12-13: Store-Item-Demand(Prophet调参(初步调试后默认参数效果最好)，XGBoost继续优化)；
- 2019-12-16: Store-Item-Demand(提交对比实际分数，XGBoost-31.42702，XGBoost(NoFE)-25.21289，prophet-14.38283）、基石-12；
- 2019-12-17: Store-Item-Demand(XGBoost目前提交分数30+，远高于不做FE的提交结果，应该是有bug，修复问题优化分数，目前XGBoost-14.31967，已经在public,private上低于prophet，后续继续考虑优化(细化lag参数，目前是90,180,365，考虑细化，分析目前的模型复杂度与EinEout关系等，判断当前是欠拟合还是过拟合，验证集划分方式是否有更好的办法)，尽量到13.xxx)；
- 2019-12-18: Store-Item-Demand(分析FuturePricePredict中的处理方法(测试集、验证集都只是一个月的数据，因此计算是lag1也是有值的，从这个角度看，目前的lag90开始是没问题的，只不过因为步长过长，时间相关性没有那么强，这里要细化lag)，XGBoost参数优化，矫正因子，判断过欠拟合，目前XGBoost-14.16492)，基石-13，14；
- 2019-12-19: Store-Item-Demand(XGBoost调参)、基石-15、手写识别(绘制图片，增加旋转缩放等新数据hinting，018hv3v)、L1和L2正则化；
- 2019-12-20: 基石-16(回顾基石课程)、手写识别提交(结束)、Store-Item-Demand(继续调参)；
- 2019-12-21: 基石-16、技法-01(linear SVM)；
- 2019-12-22: 技法-02(WTF),03(WTF)、Store-Item-Demand(修改参数运行(目前看应该是存在bug，对比下跟之前最好的version，目前过拟合非常严重)，该项目似乎有验证集污染问题，平均特征计算时使用了训练+验证的数据，但是这部分数据理应是不可见的)与手写识别(注意之前方式没有保留原始训练数据，导致分数偏低，现在加上，离线运行，修改验证集划分时机避免数据增强的污染)；
- 2019-12-23: Store-Item-Demand(过拟合debug，数据污染问题关注)、Recruit Restaurant Visitor Forecasting(开始，提交初版)；
- 2019-12-25: Store-Item-Demand(暂停)、Recruit Restaurant Visitor Forecasting(EDA+FE，由于其店铺数据特点、时间不连续等，仍需要处理，该数据更接近生产数据)；
- 2019-12-26: Recruit Restaurant Visitor Forecasting(手动填充缺失日期row，训练并提交第一版)、技法-04(技法目前看起来有压力，先从西瓜书的线性模型章节开始补一下基础知识)；
- 2019-12-27: Store-Item-Demand(修复验证数据集大小问题、调整划分方式为通过与固定datetime比对、运行提交)、Recruit Restaurant Visitor Forecasting(整理运行提交)；
- 2019-01-01: 微积分(第一章)；
- 2019-01-02: 微积分(完成第一章、第二章)、Recruit Restaurant Visitor Forecast(目前得分很低，分析原因，修复问题)；
- 2019-01-03: 微积分(完成第二章)；
- 2019-01-06: 微积分(完成第三章)、Recruit Restaurant Visitor Forecast(继续分析问题)、Web Traffic Forecast(启动)；
- 2019-01-07: 微积分(完成第四章)、发布Wechat+到[HelloGithub](https://hellogithub.com/)；
- 2019-01-08: 微积分(完成第五章)；
