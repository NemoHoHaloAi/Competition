# PLANS

All I did in last two years:
- form `2017-10-25` to `2018-10-18`, 1 year, I done the ML class and ML+ class.
- from `2018-10-19` to `2019-11-05`, 1 year, I only done 3 projects(Titanic, House-Price, DigitReconize), starting 2 projects(ASHRA, Future-Sales-Predict) in kaggle.

In one and half years ago, I writed this:

> **Get a job about machine learning whatever how much job-pay is!!!**<br>
>> I am 26 old now, I have nothing by myself to proud. The house? my parent pay it, the job? it just so-so. I am even not better than my father on his 26 old, and I have University degree. So what I do in shenzhen from 2015 year until now. Everyone I know is working hard but me, I feel shame on myself. But good news is I still have time to find and learn how to be better. Someone will say I just follow the wind of machine learning, but I dont give a shit, it will be difficult, and job-pay will be lesser, but I will get it and do it well, I will show everyone I can do this well. Of cause first I must to finish the udacity machine learning lesson.
    
And now, I am 27, still do nothing, I am scare now, maybe this is a wrong way and I am not a hard-work person, maybe I should always be a software-engineer not a MLer, but I want to try last time, from now to `2020-05-01`, I will study harder and harder, follow my plan(kaggle projects, kaggle kernels, books and videos), I will give up if I can not get a ML job between `2020-03` and `2020-04`, please be harder and dont make yourself regretting, when you feel tired, you look around your friends(xing, qi, rui), everybody work hard and get something except for you, you should work harder than them.

## TARGET

Get a job about `Time-Series`, `Sale-Predict` and `Machine Learning`.

## Timetable

- work day:
    - `9:00` ~ `10:00`: relax;
    - `10:00` ~ `12:30`: work;
    - `12:30` ~ `14:00`: lunch and take a nap;
    - `14:00` ~ `19:30`: work;
    - `19:30` ~ `21:00`: dinner and take a shower;
    - `21:00` ~ `24:00`: study;
- rest day:
    - `10:00` ~ `12:00`: relax;
    - `12:00` ~ `14:00`: breakfast and take a walk and shop for dinner;
    - `14:00` ~ `18:00`: study;
    - `18:00` ~ `20:00`: dinner and take a shower and maybe take a walk;
    - `20:00` ~ `24:00`: study;
    
## DETAIL

When you waiting for the code run, you best to do something else, like learn from kernels, read book, watch video, write note, etc.

## PLAN-corgi ![icon](https://img.shields.io/badge/doing-60%25-green)

cycle time: from `2019-11-05` to `2019-11-30`;

0. ![icon](https://img.shields.io/badge/todo|A-90%25-green) finish [future-price-predict project](https://www.kaggle.com/holoong9291/predict-future-sales) with the good kernel
    1. deathline: `2019-11-10`;
    2. now: fix and update with [the good kernel](https://www.kaggle.com/dlarionov/feature-engineering-xgboost);
    3. and: model stack, correct factor;
    4. last: up to Top10%;
1. ![icon](https://img.shields.io/badge/done-100%25-lightgrey) learn how to work with time series with TS kernels
    1. deathline: `2019-11-17`;
    2. now: start with https://www.kaggle.com/shivamb/data-science-glossary-on-kaggle ;
    3. first(common): https://www.kaggle.com/thebrownviking20/everything-you-can-do-with-a-time-series ;
    4. second(ARIMA): https://www.kaggle.com/myonin/bitcoin-price-prediction-by-arima ;
2. ![icon](https://img.shields.io/badge/doing|S-10%25-green) another competitions
    - [NFL Big Data Bowl](https://www.kaggle.com/c/nfl-big-data-bowl-2020/data)
        1. deathline: `2019-11-28`;
        2. [github project link](https://github.com/NemoHoHaloAi/Competition/tree/master/kaggle/Topxxx-yyy-zzz-NFL-Big-Data-Bowl)
        3. [start with](https://www.kaggle.com/gertjac/regression-approach)
    - [Walmart Recruiting II: Sales in Stormy Weather](https://www.kaggle.com/c/walmart-recruiting-sales-in-stormy-weather)
    - [Store Item Demand Forecasting Challenge](https://www.kaggle.com/c/demand-forecasting-kernels-only)
    - [Corporación Favorita Grocery Sales Forecasting](https://www.kaggle.com/c/favorita-grocery-sales-forecasting)
3. ![icon](https://img.shields.io/badge/todo|B-33%25-green) [summary](https://github.com/NemoHoHaloAi/Competition/tree/master/memo/Time-Series) of time-series projects(House-Price, Rossmann, Predict-Future-Sales)
    1. deathline: `2019-11-13`;
    2. target: can throw into the introduction;
4. ![icon](https://img.shields.io/badge/done-100%25-lightgrey) summary of time-series kernels(Time-Series projects)
    1. deathline: `2019-11-20`;
5. ![icon](https://img.shields.io/badge/todo-0%25-orange) summary of time-series(All about Time-Series)
    1. deathline: `2019-11-25`;
4. ![icon](https://img.shields.io/badge/todo-0%25-orange) update introduction with some project, and add detail in project
    1. deathline: `2019-11-30`;
    2. target: can give it to the interviewers and show my Time-Series skills;

## PLAN-jaguar ![icon](https://img.shields.io/badge/todo-5%25-orange)

cycle time: from `2019-12-01` to `2019-12-31`;

0. [autoML](https://www.kaggle.com/practical-model-evaluation?utm_medium=email&utm_source=intercom&utm_campaign=model-evaluation-workshop)
1. Learn theoretical knowledge about ML
    1. 李航《统计学习方法》+[code](https://github.com/WenDesi/lihang_book_algorithm)：建议边看书边手推公式然后对着GitHub一边敲代码;
    2. 林轩田《机器学习基石》+[video+link+note](https://github.com/NemoHoHaloAi/NTU-HsuanTienLin-MachineLearning/tree/master/Machine%20Learning%20Foundations);
    3. 林轩田《机器学习技法》+[video+link+note](https://github.com/NemoHoHaloAi/NTU-HsuanTienLin-MachineLearning/tree/master/Machine%20Learning%20Techniques);
    4. [线性代数和微积分](https://github.com/NemoHoHaloAi/OpenCourseCatalog);
    5. [Spark in Python](http://spark.apache.org/docs/latest/api/python/index.html);

## DAILY MEMO

同时进行的事：NFL、KernelLearn、基石课程；

- 2019-11-06: 完成Future-Sales-Predict项目从good-kernel上借鉴部分，目前完成了预处理、特征工程部分；
- 2019-11-07: 完成数据分割、baseline、遍历方式优化部分、数据转换（对比多种方式并分别应用到特征上）、数据转换无法降低skew的原因及处理方法、绘制整个过程中的数据结构变化；
- 2019-11-08: 数据转换后转换回来的问题、调整数据转换代码到合入test前并分别对matrix和train做转换、数据结构变化收尾；
- 2019-11-09: 基石-chapter2，基石-chapter3；
- 2019-11-10: 预测结果与实际结果对比、生成结果文件、计算分数(0.95)、模型堆叠、开放kernel并增加baseon和优化修改点，基石-chapter4，基石-chapter5，基石-chapter6；
- 2019-11-11: 离线运行Future-Sales-Predict、Kernel(基于TS数据能做的所有事)；
- 2019-11-12: Kernel(基于TS数据能做的所有事)-surplus；
- 2019-11-13: Kernel(Bitcoin-Predict-by-ARIMA)；
- 2019-11-14: Kernel(Bert NFL started Kernel)、NFL-Big-Data-Bowl(开始、数据加载、定义问题、评价函数、Preprocess)；
- 2019-11-15: NFL-Big-Data-Bowl(调研理解数据和问题、Preprocess)；
- 2019-11-16: NFL-Big-Data-Bowl(EDA、FE（FE部分暂时不考虑聚合的球员信息挖掘）)；
- 2019-11-17: NFL-Big-Data-Bowl(聚合后球员信息挖掘、算法替换为性能更好的，比如xgboost、模型堆叠集成)；
- 2019-11-18: NFL-Big-Data-Bowl(还有几个需要处理的特征：Location，PlayerCollegeName，Stadium，GameWeather，OffensePersonnel，DefensePersonnel，统一处理这一类问题，test中的类别不存在train中时如何处理、设计新的特征提交结果)；
- 2019-11-19: 修复一些bug，提交结果、score上看没有提升；
- 2019-11-20: 开始在22个球员的位置、速度、角度等信息上进行挖掘，得到的信息不足以提高模型的准确性；
- 2019-11-24: 开始考虑用简单特征、复杂模型来处理，基石-chapter7、8、9；
- 2019-11-25~27: 离线运行、分kernel验证、模型融合；
- 2019-11-28: Future-Sales-Predict提高到20%；
